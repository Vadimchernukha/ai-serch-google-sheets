Metadata-Version: 2.4
Name: top-scraper
Version: 0.1.0
Summary: CLI tool for enriching company data from Google Sheets
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: beautifulsoup4>=4.12.3
Requires-Dist: gspread>=6.0.0
Requires-Dist: httpx>=0.27.0
Requires-Dist: loguru>=0.7.2
Requires-Dist: openai>=1.46.0
Requires-Dist: pandas>=2.2.3
Requires-Dist: playwright>=1.47.0
Requires-Dist: pydantic>=2.8.2
Requires-Dist: pydantic-settings>=2.4.0
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: tiktoken>=0.7.0
Requires-Dist: tenacity>=9.0.0
Requires-Dist: tqdm>=4.66.5
Provides-Extra: news
Requires-Dist: newsapi-python>=0.2.7; extra == "news"

# Top Scraper

CLI для массового обогащения данных о компаниях из Google Sheets.

## Быстрый старт

1. `python3.11 -m venv .venv && source .venv/bin/activate`
2. `pip install -r requirements.txt`
3. Скопируй `config/env.example` в `.env` и заполни ключи.
4. `playwright install chromium`
5. `python -m src.main --limit 10` (для теста на первых строках)

## Архитектура

- `src/config.py` — загрузка настроек из .env (pydantic).
- `src/google_sheet.py` — чтение/запись Google Sheets, бэкапы.
- `src/pipeline/enricher.py` — основной пайплайн обогащения.
- `src/sources/` — HTTP-скрапинг и внешние API (SerpAPI, NewsAPI).
- `src/nlp/llm.py` — обёртка вокруг OpenAI/Perplexity для саммари.
- `src/utils/` — нормализация данных, эвристики.
- `reports/` — локальные бэкапы JSON/CSV после запуска.

## Запуск

```bash
python -m src.main --limit 50 --resume
```

Флаги `--limit` и `--resume` опциональны. Логирование идёт в консоль, ошибки пишутся вместе с трейсами.

## Переменные окружения

Смотри `config/env.example`. Ключи Google берутся из JSON сервисного аккаунта в виде строки целиком.

## Использование Perplexity

Укажи `PERPLEXITY_API_KEY`, если нужно fallback на Perplexity для саммари или поиска новостей, когда сайт не даёт данных.
# Top Scraper

Консольный инструмент для обогащения списка компаний из Google Sheets свежими сводками, инсайтами, новостями и продуктовой информацией.

## Быстрый старт

1. Создай виртуальное окружение и установи зависимости:

   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   playwright install chromium
   ```

2. Скопируй `env.template` в `.env` и заполни переменные (JSON сервисного аккаунта, ID таблицы и т.д.).

3. Запусти CLI:

   ```bash
   python -m src.main --limit 20
   ```

   Дополнительные флаги смотри в `python -m src.main --help`.

## Архитектура

- `src/main.py` — точка входа, аргументы, прогресс, файлы отчётов
- `src/config.py` — загрузка .env, валидация настроек
- `src/google_sheet.py` — работа с Google Sheets API
- `src/pipeline/enricher.py` — основной конвейер обогащения
- `src/sources/*` — клиенты для сайтов и внешних API
- `src/nlp/llm.py` — генерация саммари и инсайтов
- `src/utils/text.py` — утилиты обработки текста

## TODO

- добавить кэширование результатов API (sqlite/redis)
- прикрутить юнит-тесты для парсеров
- расширить детект продуктов

